{
    "docs": [
        {
            "location": "/", 
            "text": "Cypress Synopsis\n\n\nCypress is an experimental design engine for internetworked cyber-physical systems. An internetworked cyber-physical (ICPS) system typically is made up of the following.\n\n\n\n\nComputer Networks\n\n\nPhysical Networks\n\n\nSensors \n Actuators\n\n\nDistributed Monitoring \n Control Software\n\n\n\n\nTake for example, the power grid. Computer networks comprise the computers, routers, and switches that interconnect substations and subsequently monitoring and control systems. Physical networks comprise the generators, transformers, transmission lines, busbars and load centres that connect society to electric power. Sensors and actuators are the conduit by which the computer and physical are themselves connected. Taken together these components are an ICPS.\n\n\nCypress allows users to design ICPS system experiments and instantiate them in a hybrid simulated-physical emulated-cyber (SPEC) environment. This is accomplished through the combination of the following.\n\n\n\n\nGraphical Modeling Environment\n\n\nICPS Data Model \n\n\nICPS Model Analysis and Interrogation Algorithm Suite\n\n\nAutomated Experimentation Runtime\n\n\nSimulation Engine for Network Control Environments\n\n\nDeterLab Emulated Network Environment\n\n\n\n\nAbout This Document\n\n\nThis document covers the design and implementation of the Cypress experimental design engine. Cypress is the first of its kind. To date there are many tools for building physical control systems such as Matlab/Simulink, System Modeler, Dymola, Modelica etc. Many of these environments even include simple simulated communication models. What Cypress provides that is new is emulated cyber environment integration with a simulation engine purpose built for that task. Pragmatically what this provides is an increase in fidelity. Control algorithms are implemented as real distributed software that executes in a real network environment on real operating systems that have all the quirks of real networking stacks. What this also means is that \ncyber environment design\n is a first class citizen in the overall system design space. From the designs, to the data models, to the execution environment itself, Cypress is a truly cyber-physical platform.", 
            "title": "Intro"
        }, 
        {
            "location": "/#cypress-synopsis", 
            "text": "Cypress is an experimental design engine for internetworked cyber-physical systems. An internetworked cyber-physical (ICPS) system typically is made up of the following.   Computer Networks  Physical Networks  Sensors   Actuators  Distributed Monitoring   Control Software   Take for example, the power grid. Computer networks comprise the computers, routers, and switches that interconnect substations and subsequently monitoring and control systems. Physical networks comprise the generators, transformers, transmission lines, busbars and load centres that connect society to electric power. Sensors and actuators are the conduit by which the computer and physical are themselves connected. Taken together these components are an ICPS.  Cypress allows users to design ICPS system experiments and instantiate them in a hybrid simulated-physical emulated-cyber (SPEC) environment. This is accomplished through the combination of the following.   Graphical Modeling Environment  ICPS Data Model   ICPS Model Analysis and Interrogation Algorithm Suite  Automated Experimentation Runtime  Simulation Engine for Network Control Environments  DeterLab Emulated Network Environment", 
            "title": "Cypress Synopsis"
        }, 
        {
            "location": "/#about-this-document", 
            "text": "This document covers the design and implementation of the Cypress experimental design engine. Cypress is the first of its kind. To date there are many tools for building physical control systems such as Matlab/Simulink, System Modeler, Dymola, Modelica etc. Many of these environments even include simple simulated communication models. What Cypress provides that is new is emulated cyber environment integration with a simulation engine purpose built for that task. Pragmatically what this provides is an increase in fidelity. Control algorithms are implemented as real distributed software that executes in a real network environment on real operating systems that have all the quirks of real networking stacks. What this also means is that  cyber environment design  is a first class citizen in the overall system design space. From the designs, to the data models, to the execution environment itself, Cypress is a truly cyber-physical platform.", 
            "title": "About This Document"
        }, 
        {
            "location": "/arch/", 
            "text": "The cypress architecture provides three broad categories of capabilities to ICPS experiment designers; design, execution and analysis. The implementation of these capabilities comes together as a distributed server system that is depicted in the diagram below. In the sections that follow, the function of each component is described and how it participates with others. The internal design of these components is discussed in detail in later sections dedicated to that purpose.\n\n\n\n\nWeb\n\n\nThe \nweb\n server serves the Cypress design web application as well as proxies https-rest API calls to \naddie\n. The proxy part is important as this is the only publicly addressed machine (for Cypress) in the whole architecture, and it is also necessary for the web application to access the services provided by \naddie\n without going cross-domain. This also provides a single uniform access scheme for third party tools, for the reference implementation of cypress at \nISI\n, this machine will be \ncypress.deterlab.net\n.\n\n\nAddie\n\n\naddie\n stands for \nautomated design deployment interaction and execution\n. \naddie\n is the core component of the Cypress architecture. As can been seen from the annotations, there are quite a few services that fall under the purview of \naddie\n. The services listed in blue comprise the Cypress API. At this time the only user of this API is the design web-application, however the APIs have been designed for multi tool/front-end usage.\n\n\naddie\n is also home to the logic for interacting with the DeterLab network testbed environment. These responsibilities include translation of the cyber portions of Cypress data models into DeterLab TopDL models, coordinating the deployment and execution of control software and simulation programs with the DeterLab swap-in process, providing the design web-application with access to runtime experiment objects, and the execution of experiment timelines.\n\n\nFinally, \naddie\n is also responsible for generating Cypress physics simulation programs. Cypress generates multiple-program-multiple-data (MPMD) distributed simulation code for each experiment based on the physical network model. When an API call comes in to execute an experiment, \naddie\n extracts a raw system of differential-algebraic equations (DAE) from the physical network model, creates a pseudo-optimal clustering of equations and variables from the DAE system and generates the MPMD programs based on this clustering. The execution of these programs is then orchestrated as a part of \naddie\n's interaction with the DeterLab swap-in procedure.\n\n\nAll of the data held in \naddie\n services is soft state, anything that is persistent is stored in \ndata\n using a remote SQL API from \naddie\n. This was a design choice to allow for both good performance of \naddie\n services by having in-memory representations of experiment components that are actively being worked on, but also for providing a bit of fault tolerance by allowing services to restart from known good state in the \ndata\n. In the cloud sense, \naddie\n would be considered the tier-1 services.\n\n\nData\n\n\nThe \ndata\n servers hold Cypress' persistent data. The storage mechanism is simply a PostgreSQL database. The data servers are actually \ndata0\n and \ndata1\n where \ndata\n resolves to \ndata0\n under normal operating conditions. The servers are located at physically different sites and use PostgreSQL's master-to-master replication over SSH for replication.\n\n\nDeterLab\n\n\nDeterLab is home to the emulated cyber network environment. Everything in \ntestbed\n is under the control of DeterLab.\n\n\nUsers\n\n\nusers\n is where user data is housed that can be accessed both from the outside world and from active experiments running on DeterLab. This is the place where Cypress designers place control code and custom deployment scripts for launching that code.\n\n\nBoss\n\n\nboss\n orchestrates the execution of the DeterLab testbed. On receipt of a network environment description, \nboss\n is ultimately responsible for creating the representative network environment. It does this by allocating computers and network resources within the testbed, creating VLANs for isolation and connectivity and setting up the computers operating systems to integrate with the DeterLab runtime environment for things like \nusers\n access and reporting back to \nboss\n with things like node readiness and lifecycle information.\n\n\nTestbed\n\n\nThe \ntestbed\n is a collection of computers and networking equipment that is configured by DeterLab in response to experiment swap-ins and swap-outs. For cypress there are a set of nodes (computers) within the \ntestbed\n that are especially reserved for simulation, this is called the \nkrylov\n cluster.\n\n\nKrylov\n\n\nThe \nkrylov\n cluster is a set of nodes specifically designed and configured for running physics simulations. These nodes have specially configured operating systems, high-performance hardware and compilers and network interconnects. The allocation and management of these nodes is a coordinated between \naddie\n and \nboss", 
            "title": "Architecture"
        }, 
        {
            "location": "/arch/#web", 
            "text": "The  web  server serves the Cypress design web application as well as proxies https-rest API calls to  addie . The proxy part is important as this is the only publicly addressed machine (for Cypress) in the whole architecture, and it is also necessary for the web application to access the services provided by  addie  without going cross-domain. This also provides a single uniform access scheme for third party tools, for the reference implementation of cypress at  ISI , this machine will be  cypress.deterlab.net .", 
            "title": "Web"
        }, 
        {
            "location": "/arch/#addie", 
            "text": "addie  stands for  automated design deployment interaction and execution .  addie  is the core component of the Cypress architecture. As can been seen from the annotations, there are quite a few services that fall under the purview of  addie . The services listed in blue comprise the Cypress API. At this time the only user of this API is the design web-application, however the APIs have been designed for multi tool/front-end usage.  addie  is also home to the logic for interacting with the DeterLab network testbed environment. These responsibilities include translation of the cyber portions of Cypress data models into DeterLab TopDL models, coordinating the deployment and execution of control software and simulation programs with the DeterLab swap-in process, providing the design web-application with access to runtime experiment objects, and the execution of experiment timelines.  Finally,  addie  is also responsible for generating Cypress physics simulation programs. Cypress generates multiple-program-multiple-data (MPMD) distributed simulation code for each experiment based on the physical network model. When an API call comes in to execute an experiment,  addie  extracts a raw system of differential-algebraic equations (DAE) from the physical network model, creates a pseudo-optimal clustering of equations and variables from the DAE system and generates the MPMD programs based on this clustering. The execution of these programs is then orchestrated as a part of  addie 's interaction with the DeterLab swap-in procedure.  All of the data held in  addie  services is soft state, anything that is persistent is stored in  data  using a remote SQL API from  addie . This was a design choice to allow for both good performance of  addie  services by having in-memory representations of experiment components that are actively being worked on, but also for providing a bit of fault tolerance by allowing services to restart from known good state in the  data . In the cloud sense,  addie  would be considered the tier-1 services.", 
            "title": "Addie"
        }, 
        {
            "location": "/arch/#data", 
            "text": "The  data  servers hold Cypress' persistent data. The storage mechanism is simply a PostgreSQL database. The data servers are actually  data0  and  data1  where  data  resolves to  data0  under normal operating conditions. The servers are located at physically different sites and use PostgreSQL's master-to-master replication over SSH for replication.", 
            "title": "Data"
        }, 
        {
            "location": "/arch/#deterlab", 
            "text": "DeterLab is home to the emulated cyber network environment. Everything in  testbed  is under the control of DeterLab.", 
            "title": "DeterLab"
        }, 
        {
            "location": "/arch/#users", 
            "text": "users  is where user data is housed that can be accessed both from the outside world and from active experiments running on DeterLab. This is the place where Cypress designers place control code and custom deployment scripts for launching that code.", 
            "title": "Users"
        }, 
        {
            "location": "/arch/#boss", 
            "text": "boss  orchestrates the execution of the DeterLab testbed. On receipt of a network environment description,  boss  is ultimately responsible for creating the representative network environment. It does this by allocating computers and network resources within the testbed, creating VLANs for isolation and connectivity and setting up the computers operating systems to integrate with the DeterLab runtime environment for things like  users  access and reporting back to  boss  with things like node readiness and lifecycle information.", 
            "title": "Boss"
        }, 
        {
            "location": "/arch/#testbed", 
            "text": "The  testbed  is a collection of computers and networking equipment that is configured by DeterLab in response to experiment swap-ins and swap-outs. For cypress there are a set of nodes (computers) within the  testbed  that are especially reserved for simulation, this is called the  krylov  cluster.", 
            "title": "Testbed"
        }, 
        {
            "location": "/arch/#krylov", 
            "text": "The  krylov  cluster is a set of nodes specifically designed and configured for running physics simulations. These nodes have specially configured operating systems, high-performance hardware and compilers and network interconnects. The allocation and management of these nodes is a coordinated between  addie  and  boss", 
            "title": "Krylov"
        }, 
        {
            "location": "/dev/", 
            "text": "Getting Started\n\n\nIntegration Tests", 
            "title": "Development"
        }, 
        {
            "location": "/dev/#getting-started", 
            "text": "", 
            "title": "Getting Started"
        }, 
        {
            "location": "/dev/#integration-tests", 
            "text": "", 
            "title": "Integration Tests"
        }, 
        {
            "location": "/web/", 
            "text": "Design\n\n\nUser API\n\n\nInternal API", 
            "title": "Modeling Environment"
        }, 
        {
            "location": "/web/#design", 
            "text": "", 
            "title": "Design"
        }, 
        {
            "location": "/web/#user-api", 
            "text": "", 
            "title": "User API"
        }, 
        {
            "location": "/web/#internal-api", 
            "text": "", 
            "title": "Internal API"
        }, 
        {
            "location": "/addie/", 
            "text": "Design\n\n\nSoftstate Data Tier\n\n\nData Model\n\n\nExperiment Design CRUD API\n\n\nExperiment Design QA API\n\n\nExperiment Result QA API\n\n\nExperiment Runtime API\n\n\nInternal Code Docs", 
            "title": "Addie"
        }, 
        {
            "location": "/addie/#design", 
            "text": "", 
            "title": "Design"
        }, 
        {
            "location": "/addie/#softstate-data-tier", 
            "text": "", 
            "title": "Softstate Data Tier"
        }, 
        {
            "location": "/addie/#data-model", 
            "text": "", 
            "title": "Data Model"
        }, 
        {
            "location": "/addie/#experiment-design-crud-api", 
            "text": "", 
            "title": "Experiment Design CRUD API"
        }, 
        {
            "location": "/addie/#experiment-design-qa-api", 
            "text": "", 
            "title": "Experiment Design QA API"
        }, 
        {
            "location": "/addie/#experiment-result-qa-api", 
            "text": "", 
            "title": "Experiment Result QA API"
        }, 
        {
            "location": "/addie/#experiment-runtime-api", 
            "text": "", 
            "title": "Experiment Runtime API"
        }, 
        {
            "location": "/addie/#internal-code-docs", 
            "text": "", 
            "title": "Internal Code Docs"
        }, 
        {
            "location": "/data/", 
            "text": "", 
            "title": "Data"
        }, 
        {
            "location": "/sim/", 
            "text": "", 
            "title": "Simulation"
        }
    ]
}